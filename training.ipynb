{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rohan-Kumar-Singh/Sentiment-analysis-of-informal-text/blob/master/training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BP9yhN7BTDS",
        "outputId": "b368d5e8-8c9e-4be3-f96c-283e0fe0d068"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gu5ATE3SuLoL",
        "outputId": "b90bcfa2-7b26-4311-e680-7ed91b3ff096"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFPneZrxuNW1",
        "outputId": "e02dd754-1bd2-4739-dcc9-948d065f81a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla K80\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJ5ef0gxlTRc",
        "outputId": "64a31ede-d2a7-4eef-c48e-1f7da2d9d8c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.0 MB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6.6 MB 33.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 880 kB 41.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 77 kB 6.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 596 kB 42.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=62c43bebffee65f47e0a06c90f49c1068ccfb3f5aa98fa5f20dd85edbc7a7e22\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.5.1 pyyaml-6.0 sacremoses-0.0.53 tokenizers-0.12.1 transformers-4.18.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "aw1fjLSYlrf_",
        "outputId": "1de21613-2ad2-4b37-cc9e-6d50953ae2fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of training sentences: 21,213\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f2983c66-22e7-4ba2-b5a9-3216d7406af0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>User</th>\n",
              "      <th>Tweet</th>\n",
              "      <th>cleaned_tweets</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TanseemHaider</td>\n",
              "      <td>RT @aajtak: ‡§ú‡•à‡§ï‡§≤‡•Ä‡§® ‡§´‡§∞‡•ç‡§®‡§æ‡§Ç‡§°‡•Ä‡§∏ ‡§®‡•á ‡§ï‡•ã‡§∞‡•ç‡§ü ‡§∏‡•á 15 ‡§¶‡§ø...</td>\n",
              "      <td>RT  ‡§ú‡•à‡§ï‡§≤‡•Ä‡§® ‡§´‡§∞‡•ç‡§®‡§æ‡§Ç‡§°‡•Ä‡§∏ ‡§®‡•á ‡§ï‡•ã‡§∞‡•ç‡§ü ‡§∏‡•á  ‡§¶‡§ø‡§® ‡§ï‡•á ‡§µ‡§ø‡§¶‡•á‡§∂...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sanjayyadav782</td>\n",
              "      <td>RT @OpIndia_in: ‚Äò‡§¨‡•â‡§≤‡•Ä‡§µ‡•Å‡§° ‡§Æ‡•Å‡§ù‡•á ‡§Ö‡§´‡•â‡§∞‡•ç‡§° ‡§®‡§π‡•Ä‡§Ç ‡§ï‡§∞ ‡§∏...</td>\n",
              "      <td>RT  ‚Äò‡§¨‡•â‡§≤‡•Ä‡§µ‡•Å‡§° ‡§Æ‡•Å‡§ù‡•á ‡§Ö‡§´‡•â‡§∞‡•ç‡§° ‡§®‡§π‡•Ä‡§Ç ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§â‡§®‡§ï‡•Ä ‡§´‡§º‡§ø...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>chetanjoshi_</td>\n",
              "      <td>RT @thepaltan_: ‡§∏‡§Ç‡§µ‡•á‡§¶‡§®‡§∂‡•Ä‡§≤ ‡§Æ‡•Å‡§¶‡•ç‡§¶‡•ã‡§Ç ‡§™‡§∞ ‡§∏‡•É‡§ú‡§®‡§æ‡§§‡•ç‡§Æ‡§ï...</td>\n",
              "      <td>RT  ‡§∏‡§Ç‡§µ‡•á‡§¶‡§®‡§∂‡•Ä‡§≤ ‡§Æ‡•Å‡§¶‡•ç‡§¶‡•ã‡§Ç ‡§™‡§∞ ‡§∏‡•É‡§ú‡§®‡§æ‡§§‡•ç‡§Æ‡§ï ‡§™‡•ç‡§∞‡§π‡§æ‡§∞ ‡§ï‡§∞‡§§‡§æ...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>thepaltan_</td>\n",
              "      <td>‡§∏‡§Ç‡§µ‡•á‡§¶‡§®‡§∂‡•Ä‡§≤ ‡§Æ‡•Å‡§¶‡•ç‡§¶‡•ã‡§Ç ‡§™‡§∞ ‡§∏‡•É‡§ú‡§®‡§æ‡§§‡•ç‡§Æ‡§ï ‡§™‡•ç‡§∞‡§π‡§æ‡§∞ ‡§ï‡§∞‡§§‡§æ ‡§∏‡§ø‡§®...</td>\n",
              "      <td>‡§∏‡§Ç‡§µ‡•á‡§¶‡§®‡§∂‡•Ä‡§≤ ‡§Æ‡•Å‡§¶‡•ç‡§¶‡•ã‡§Ç ‡§™‡§∞ ‡§∏‡•É‡§ú‡§®‡§æ‡§§‡•ç‡§Æ‡§ï ‡§™‡•ç‡§∞‡§π‡§æ‡§∞ ‡§ï‡§∞‡§§‡§æ ‡§∏‡§ø‡§®...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RajivSanatni</td>\n",
              "      <td>RT @rowdy_pandit: üí•‡§ú‡§¨ ‡§¶‡§ø‡§ñ‡•á‡§ó‡§æ ‡§§‡§≠‡•Ä ‡§§‡•ã ‡§¨‡§ø‡§ï‡•á‡§ó‡§æ!!ü§ìüôÇ...</td>\n",
              "      <td>RT  üí•‡§ú‡§¨ ‡§¶‡§ø‡§ñ‡•á‡§ó‡§æ ‡§§‡§≠‡•Ä ‡§§‡•ã ‡§¨‡§ø‡§ï‡•á‡§ó‡§æü§ìüôÇüôÇ üí•üëâSimple logic...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21208</th>\n",
              "      <td>JuliusFlywheel</td>\n",
              "      <td>RT @redrabbleroz: I honestly still cannot get ...</td>\n",
              "      <td>RT  I honestly still cannot get over this How ...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21209</th>\n",
              "      <td>gordonm25443977</td>\n",
              "      <td>RT @toryman1979: https://t.co/QDwRYKgtm7\\nTwin...</td>\n",
              "      <td>RT   Twin girls  found safe and well after goi...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21210</th>\n",
              "      <td>phorlerkemii</td>\n",
              "      <td>RT @Gistloversblog1: The comment I was looking...</td>\n",
              "      <td>RT  The comment I was looking for Firstly she ...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21211</th>\n",
              "      <td>Yashika_SidNaaz</td>\n",
              "      <td>RT @filmibeat: Tejasswi Prakash, Shehnaaz Gill...</td>\n",
              "      <td>RT  Tejasswi Prakash Shehnaaz Gill amp Anushka...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21212</th>\n",
              "      <td>WediRaya7</td>\n",
              "      <td>RT @E2buddy1: On this #MothersDay2022 Tigrayan...</td>\n",
              "      <td>RT  On this MothersDay Tigrayan mothers are go...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>21213 rows √ó 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f2983c66-22e7-4ba2-b5a9-3216d7406af0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f2983c66-22e7-4ba2-b5a9-3216d7406af0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f2983c66-22e7-4ba2-b5a9-3216d7406af0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                  User                                              Tweet  \\\n",
              "0        TanseemHaider  RT @aajtak: ‡§ú‡•à‡§ï‡§≤‡•Ä‡§® ‡§´‡§∞‡•ç‡§®‡§æ‡§Ç‡§°‡•Ä‡§∏ ‡§®‡•á ‡§ï‡•ã‡§∞‡•ç‡§ü ‡§∏‡•á 15 ‡§¶‡§ø...   \n",
              "1       sanjayyadav782  RT @OpIndia_in: ‚Äò‡§¨‡•â‡§≤‡•Ä‡§µ‡•Å‡§° ‡§Æ‡•Å‡§ù‡•á ‡§Ö‡§´‡•â‡§∞‡•ç‡§° ‡§®‡§π‡•Ä‡§Ç ‡§ï‡§∞ ‡§∏...   \n",
              "2         chetanjoshi_  RT @thepaltan_: ‡§∏‡§Ç‡§µ‡•á‡§¶‡§®‡§∂‡•Ä‡§≤ ‡§Æ‡•Å‡§¶‡•ç‡§¶‡•ã‡§Ç ‡§™‡§∞ ‡§∏‡•É‡§ú‡§®‡§æ‡§§‡•ç‡§Æ‡§ï...   \n",
              "3           thepaltan_  ‡§∏‡§Ç‡§µ‡•á‡§¶‡§®‡§∂‡•Ä‡§≤ ‡§Æ‡•Å‡§¶‡•ç‡§¶‡•ã‡§Ç ‡§™‡§∞ ‡§∏‡•É‡§ú‡§®‡§æ‡§§‡•ç‡§Æ‡§ï ‡§™‡•ç‡§∞‡§π‡§æ‡§∞ ‡§ï‡§∞‡§§‡§æ ‡§∏‡§ø‡§®...   \n",
              "4         RajivSanatni  RT @rowdy_pandit: üí•‡§ú‡§¨ ‡§¶‡§ø‡§ñ‡•á‡§ó‡§æ ‡§§‡§≠‡•Ä ‡§§‡•ã ‡§¨‡§ø‡§ï‡•á‡§ó‡§æ!!ü§ìüôÇ...   \n",
              "...                ...                                                ...   \n",
              "21208   JuliusFlywheel  RT @redrabbleroz: I honestly still cannot get ...   \n",
              "21209  gordonm25443977  RT @toryman1979: https://t.co/QDwRYKgtm7\\nTwin...   \n",
              "21210     phorlerkemii  RT @Gistloversblog1: The comment I was looking...   \n",
              "21211  Yashika_SidNaaz  RT @filmibeat: Tejasswi Prakash, Shehnaaz Gill...   \n",
              "21212        WediRaya7  RT @E2buddy1: On this #MothersDay2022 Tigrayan...   \n",
              "\n",
              "                                          cleaned_tweets    target  \n",
              "0      RT  ‡§ú‡•à‡§ï‡§≤‡•Ä‡§® ‡§´‡§∞‡•ç‡§®‡§æ‡§Ç‡§°‡•Ä‡§∏ ‡§®‡•á ‡§ï‡•ã‡§∞‡•ç‡§ü ‡§∏‡•á  ‡§¶‡§ø‡§® ‡§ï‡•á ‡§µ‡§ø‡§¶‡•á‡§∂...   Neutral  \n",
              "1      RT  ‚Äò‡§¨‡•â‡§≤‡•Ä‡§µ‡•Å‡§° ‡§Æ‡•Å‡§ù‡•á ‡§Ö‡§´‡•â‡§∞‡•ç‡§° ‡§®‡§π‡•Ä‡§Ç ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§â‡§®‡§ï‡•Ä ‡§´‡§º‡§ø...  Negative  \n",
              "2      RT  ‡§∏‡§Ç‡§µ‡•á‡§¶‡§®‡§∂‡•Ä‡§≤ ‡§Æ‡•Å‡§¶‡•ç‡§¶‡•ã‡§Ç ‡§™‡§∞ ‡§∏‡•É‡§ú‡§®‡§æ‡§§‡•ç‡§Æ‡§ï ‡§™‡•ç‡§∞‡§π‡§æ‡§∞ ‡§ï‡§∞‡§§‡§æ...   Neutral  \n",
              "3      ‡§∏‡§Ç‡§µ‡•á‡§¶‡§®‡§∂‡•Ä‡§≤ ‡§Æ‡•Å‡§¶‡•ç‡§¶‡•ã‡§Ç ‡§™‡§∞ ‡§∏‡•É‡§ú‡§®‡§æ‡§§‡•ç‡§Æ‡§ï ‡§™‡•ç‡§∞‡§π‡§æ‡§∞ ‡§ï‡§∞‡§§‡§æ ‡§∏‡§ø‡§®...   Neutral  \n",
              "4      RT  üí•‡§ú‡§¨ ‡§¶‡§ø‡§ñ‡•á‡§ó‡§æ ‡§§‡§≠‡•Ä ‡§§‡•ã ‡§¨‡§ø‡§ï‡•á‡§ó‡§æü§ìüôÇüôÇ üí•üëâSimple logic...  Positive  \n",
              "...                                                  ...       ...  \n",
              "21208  RT  I honestly still cannot get over this How ...  Negative  \n",
              "21209  RT   Twin girls  found safe and well after goi...   Neutral  \n",
              "21210  RT  The comment I was looking for Firstly she ...   Neutral  \n",
              "21211  RT  Tejasswi Prakash Shehnaaz Gill amp Anushka...  Positive  \n",
              "21212  RT  On this MothersDay Tigrayan mothers are go...  Negative  \n",
              "\n",
              "[21213 rows x 4 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "# import pytreebank\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv('/content/drive/MyDrive/major-final/twitter_data_final.csv', lineterminator='\\n')\n",
        "# Report the number of sentences.\n",
        "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "# df['truth'] = df['truth'].str.replace('__label__', '')\n",
        "# df['truth'] = df['truth'].astype(int).astype('category')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zNlZ7Oi6wvx9"
      },
      "outputs": [],
      "source": [
        "df.rename(columns={'target': 'sentiment'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "YxOJbZKf8yjP",
        "outputId": "340f05e9-c715-4ef1-a1e7-1030202c72e0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fd6be318150>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuAAAAE9CAYAAABKltdlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAZOElEQVR4nO3dfbRmVX0f8O9PRnyL8iJTGwE7LCV1oTGIE0RpGhuyAEkixuJLlqmjYYW0IRrTmpZkdQWjscVlDEETbVmCQpoVIGgjSYyEgmmsDcighDdrnPgSIKijg6hRVMivfzxn9BFn4N7x3v3Mnfl81rrrnrPP3mfvw1qb+53z7Oec6u4AAABjPGjRAwAAgL2JAA4AAAMJ4AAAMJAADgAAAwngAAAwkAAOAAADrVv0AEY76KCDesOGDYseBgAAe7Drrrvuc929fkfH9roAvmHDhmzevHnRwwAAYA9WVZ/a2TFLUAAAYCABHAAABhLAAQBgIAEcAAAGEsABAGAgARwAAAYSwAEAYKBVC+BVdX5VfbaqbporO7Cqrqiqj02/D5jKq6reVFVbquqGqjpqrs2mqf7HqmrTXPnTqurGqc2bqqpW61oAAGClrOYd8HckOfE+ZWckubK7D09y5bSfJM9Ocvj0c1qStyazwJ7kzCRPT3J0kjO3h/apzs/OtbtvXwAAsNtZtQDe3X+ZZNt9ik9OcsG0fUGS586VX9gzVyfZv6q+N8kJSa7o7m3dfWeSK5KcOB17VHdf3d2d5MK5cwEAwG5r9Brwx3T3HdP2p5M8Zto+OMmtc/Vum8rur/y2HZQDAMBubd2iOu7urqoe0VdVnZbZ0pY87nGPG9ElMMjfveb7Fz0EWBGP+7UbFz0EYJDRd8A/My0fyfT7s1P57UkOnat3yFR2f+WH7KB8h7r73O7e2N0b169f/11fBAAA7KrRAfyyJNufZLIpybvnyl8yPQ3lmCR3TUtVLk9yfFUdMH358vgkl0/HvlhVx0xPP3nJ3LkAAGC3tWpLUKrqD5I8K8lBVXVbZk8zOSvJJVV1apJPJXnBVP09SU5KsiXJV5K8LEm6e1tVvTbJtVO913T39i92/nxmT1p5WJI/m34AAGC3tmoBvLt/aieHjttB3U5y+k7Oc36S83dQvjnJk7+bMQIAwGjehAkAAAMJ4AAAMJAADgAAAwngAAAwkAAOAAADCeAAADCQAA4AAAMJ4AAAMJAADgAAAwngAAAwkAAOAAADCeAAADCQAA4AAAMJ4AAAMJAADgAAAwngAAAwkAAOAAADCeAAADCQAA4AAAMJ4AAAMJAADgAAAwngAAAwkAAOAAADCeAAADCQAA4AAAMJ4AAAMJAADgAAAwngAAAwkAAOAAADCeAAADCQAA4AAAMJ4AAAMJAADgAAAwngAAAwkAAOAAADCeAAADCQAA4AAAMJ4AAAMJAADgAAAwngAAAwkAAOAAADCeAAADCQAA4AAAMtJIBX1S9V1c1VdVNV/UFVPbSqDquqa6pqS1VdXFX7TnUfMu1vmY5vmDvPr0zlH62qExZxLQAAsBzDA3hVHZzkFUk2dveTk+yT5EVJXp/k7O5+QpI7k5w6NTk1yZ1T+dlTvVTVEVO7JyU5MclbqmqfkdcCAADLtaglKOuSPKyq1iV5eJI7kvxIkkun4xckee60ffK0n+n4cVVVU/lF3f217v5Eki1Jjh40fgAA2CXDA3h3357kN5P8XWbB+64k1yX5QnffM1W7LcnB0/bBSW6d2t4z1X/0fPkO2gAAwG5pEUtQDsjs7vVhSR6b5BGZLSFZzT5Pq6rNVbV569atq9kVAADcr0UsQfnRJJ/o7q3d/Y0k70pybJL9pyUpSXJIktun7duTHJok0/H9knx+vnwHbb5Nd5/b3Ru7e+P69etX+noAAGDJFhHA/y7JMVX18Gkt93FJbknyviSnTHU2JXn3tH3ZtJ/p+FXd3VP5i6anpByW5PAkHxx0DQAAsEvWPXCVldXd11TVpUk+lOSeJB9Ocm6SP01yUVX9xlR23tTkvCS/V1VbkmzL7Mkn6e6bq+qSzML7PUlO7+57h14MAAAs0/AAniTdfWaSM+9T/PHs4Ckm3X13kufv5DyvS/K6FR8gAACsEm/CBACAgQRwAAAYSAAHAICBBHAAABhIAAcAgIEEcAAAGEgABwCAgQRwAAAYaCEv4tkTPe2XL1z0EOC7dt0bXrLoIQDAHs8dcAAAGEgABwCAgQRwAAAYSAAHAICBBHAAABhIAAcAgIEEcAAAGEgABwCAgQRwAAAYSAAHAICBBHAAABhIAAcAgIEEcAAAGEgABwCAgQRwAAAYSAAHAICBBHAAABhIAAcAgIEEcAAAGEgABwCAgQRwAAAYSAAHAICBBHAAABhIAAcAgIEEcAAAGEgABwCAgQRwAAAYSAAHAICBBHAAABhIAAcAgIEEcAAAGEgABwCAgQRwAAAYSAAHAICBFhLAq2r/qrq0qv5fVX2kqp5RVQdW1RVV9bHp9wFT3aqqN1XVlqq6oaqOmjvPpqn+x6pq0yKuBQAAlmNRd8DPSfLe7n5ikh9I8pEkZyS5srsPT3LltJ8kz05y+PRzWpK3JklVHZjkzCRPT3J0kjO3h3YAANhdDQ/gVbVfkn+Z5Lwk6e6vd/cXkpyc5IKp2gVJnjttn5zkwp65Osn+VfW9SU5IckV3b+vuO5NckeTEgZcCAADLtog74Icl2Zrk7VX14ap6W1U9IsljuvuOqc6nkzxm2j44ya1z7W+bynZWDgAAu61FBPB1SY5K8tbufmqSf8i3lpskSbq7k/RKdVhVp1XV5qravHXr1pU6LQAALNsiAvhtSW7r7mum/UszC+SfmZaWZPr92en47UkOnWt/yFS2s/Lv0N3ndvfG7t64fv36FbsQAABYruEBvLs/neTWqvrnU9FxSW5JclmS7U8y2ZTk3dP2ZUleMj0N5Zgkd01LVS5PcnxVHTB9+fL4qQwAAHZb6xbU78uT/H5V7Zvk40leltk/Bi6pqlOTfCrJC6a670lyUpItSb4y1U13b6uq1ya5dqr3mu7eNu4SAABg+RYSwLv7+iQbd3DouB3U7SSn7+Q85yc5f2VHBwAAq8ebMAEAYCABHAAABlpSAK+qK5dSBgAA3L/7XQNeVQ9N8vAkB01PGqnp0KPipTcAALBsD/QlzJ9L8sokj01yXb4VwL+Y5HdWcVwAALBHut8A3t3nJDmnql7e3W8eNCYAANhjLekxhN395qp6ZpIN8226+8JVGhcAAOyRlhTAq+r3kjw+yfVJ7p2KO4kADgAAy7DUF/FsTHLE9FIcAABgFy31OeA3JfmnqzkQAADYGyz1DvhBSW6pqg8m+dr2wu5+zqqMCgAA9lBLDeCvXs1BAADA3mKpT0H536s9EAAA2Bss9SkoX8rsqSdJsm+SByf5h+5+1GoNDAAA9kRLvQP+yO3bVVVJTk5yzGoNCgAA9lRLfQrKN/XMHyU5YRXGAwAAe7SlLkF53tzugzJ7LvjdqzIiAADYgy31KSg/Mbd9T5JPZrYMBQAAWIalrgF/2WoPBAAA9gZLWgNeVYdU1f+sqs9OP++sqkNWe3AAALCnWeqXMN+e5LIkj51+/ngqAwAAlmGpAXx9d7+9u++Zft6RZP0qjgsAAPZISw3gn6+qn66qfaafn07y+dUcGAAA7ImWGsB/JskLknw6yR1JTkny0lUaEwAA7LGW+hjC1yTZ1N13JklVHZjkNzML5gAAwBIt9Q74U7aH7yTp7m1Jnro6QwIAgD3XUgP4g6rqgO070x3wpd49BwAAJksN0W9M8ldV9YfT/vOTvG51hgQAAHuupb4J88Kq2pzkR6ai53X3Las3LAAA2DMteRnJFLiFbgAA+C4sdQ04AACwAgRwAAAYSAAHAICBBHAAABhIAAcAgIEEcAAAGEgABwCAgQRwAAAYSAAHAICBBHAAABhIAAcAgIEEcAAAGEgABwCAgRYWwKtqn6r6cFX9ybR/WFVdU1Vbquriqtp3Kn/ItL9lOr5h7hy/MpV/tKpOWMyVAADA0i3yDvgvJvnI3P7rk5zd3U9IcmeSU6fyU5PcOZWfPdVLVR2R5EVJnpTkxCRvqap9Bo0dAAB2yUICeFUdkuTHkrxt2q8kP5Lk0qnKBUmeO22fPO1nOn7cVP/kJBd199e6+xNJtiQ5eswVAADArlnUHfDfTvIfk/zjtP/oJF/o7num/duSHDxtH5zk1iSZjt811f9m+Q7afJuqOq2qNlfV5q1bt67kdQAAwLIMD+BV9eNJPtvd143qs7vP7e6N3b1x/fr1o7oFAIDvsG4BfR6b5DlVdVKShyZ5VJJzkuxfVeumu9yHJLl9qn97kkOT3FZV65Lsl+Tzc+XbzbcBAIDd0vA74N39K919SHdvyOxLlFd194uTvC/JKVO1TUnePW1fNu1nOn5Vd/dU/qLpKSmHJTk8yQcHXQYAAOySRdwB35n/lOSiqvqNJB9Oct5Ufl6S36uqLUm2ZRba0903V9UlSW5Jck+S07v73vHDBgCApVtoAO/uv0jyF9P2x7ODp5h0991Jnr+T9q9L8rrVGyEAAKwsb8IEAICBBHAAABhod1oDDgCsEce++dhFDwFWxAde/oHhfboDDgAAAwngAAAwkAAOAAADCeAAADCQAA4AAAMJ4AAAMJAADgAAAwngAAAwkAAOAAADCeAAADCQAA4AAAMJ4AAAMJAADgAAAwngAAAwkAAOAAADCeAAADCQAA4AAAMJ4AAAMJAADgAAAwngAAAwkAAOAAADCeAAADCQAA4AAAMJ4AAAMJAADgAAAwngAAAwkAAOAAADCeAAADCQAA4AAAMJ4AAAMJAADgAAAwngAAAwkAAOAAADCeAAADCQAA4AAAMJ4AAAMJAADgAAAwngAAAwkAAOAAADDQ/gVXVoVb2vqm6pqpur6hen8gOr6oqq+tj0+4CpvKrqTVW1papuqKqj5s61aar/saraNPpaAABguRZxB/yeJP+hu49IckyS06vqiCRnJLmyuw9PcuW0nyTPTnL49HNakrcms8Ce5MwkT09ydJIzt4d2AADYXQ0P4N19R3d/aNr+UpKPJDk4yclJLpiqXZDkudP2yUku7Jmrk+xfVd+b5IQkV3T3tu6+M8kVSU4ceCkAALBsC10DXlUbkjw1yTVJHtPdd0yHPp3kMdP2wUlunWt221S2s3IAANhtLSyAV9X3JHlnkld29xfnj3V3J+kV7Ou0qtpcVZu3bt26UqcFAIBlW0gAr6oHZxa+f7+73zUVf2ZaWpLp92en8tuTHDrX/JCpbGfl36G7z+3ujd29cf369St3IQAAsEyLeApKJTkvyUe6+7fmDl2WZPuTTDYlefdc+Uump6Eck+SuaanK5UmOr6oDpi9fHj+VAQDAbmvdAvo8Nsm/SXJjVV0/lf1qkrOSXFJVpyb5VJIXTMfek+SkJFuSfCXJy5Kku7dV1WuTXDvVe013bxtzCQAAsGuGB/Du/j9JaieHj9tB/U5y+k7OdX6S81dudAAAsLq8CRMAAAYSwAEAYCABHAAABhLAAQBgIAEcAAAGEsABAGAgARwAAAYSwAEAYCABHAAABhLAAQBgIAEcAAAGEsABAGAgARwAAAYSwAEAYCABHAAABhLAAQBgIAEcAAAGEsABAGAgARwAAAYSwAEAYCABHAAABhLAAQBgIAEcAAAGEsABAGAgARwAAAYSwAEAYCABHAAABhLAAQBgIAEcAAAGEsABAGAgARwAAAYSwAEAYCABHAAABhLAAQBgIAEcAAAGEsABAGAgARwAAAYSwAEAYCABHAAABhLAAQBgIAEcAAAGEsABAGAgARwAAAZa8wG8qk6sqo9W1ZaqOmPR4wEAgPuzpgN4Ve2T5HeTPDvJEUl+qqqOWOyoAABg59Z0AE9ydJIt3f3x7v56kouSnLzgMQEAwE6t9QB+cJJb5/Zvm8oAAGC3tG7RAxihqk5Lctq0++Wq+ugix8MuOyjJ5xY9iD1Z/eamRQ+B3ZO5N8KZtegRsHsy/1ZZvWLV5t4/29mBtR7Ab09y6Nz+IVPZt+nuc5OcO2pQrI6q2tzdGxc9DtjbmHuwOObfnmmtL0G5NsnhVXVYVe2b5EVJLlvwmAAAYKfW9B3w7r6nqn4hyeVJ9klyfnffvOBhAQDATq3pAJ4k3f2eJO9Z9DgYwjIiWAxzDxbH/NsDVXcvegwAALDXWOtrwAEAYE0RwBmiqrqq3ji3/6qqevUunmv/qvr5XWz7yao6aFfawlqwknPtAfr51fvs/9+V7gPWqqq6t6qur6qbquoPq+rhy2z/2Kq6dNo+sqpOmjv2nKo6Y6XHzFgCOKN8LcnzVij87p9khwG8qtb89xrgu7SSc+3+fFsA7+5nrnJ/sJZ8tbuP7O4nJ/l6kn+7nMbd/ffdfcq0e2SSk+aOXdbdZ63cUFkEAZxR7snsiyS/dN8DVbW+qt5ZVddOP8dO5a+uqlfN1bupqjYkOSvJ46e7C2+oqmdV1fur6rIkt0x1/6iqrquqm6cXMcHeYlfm2vqqumKaL2+rqk9tD/A7mktVdVaSh01z8Pensi9Pvy+qqh+b6/MdVXVKVe0zzddrq+qGqvq5Vf8vAbuH9yd5QlUdOM2nG6rq6qp6SpJU1Q9Pc+n6qvpwVT2yqjZMf/P2TfKaJC+cjr+wql5aVb9TVftNc/VB03keUVW3VtWDq+rxVfXeae6+v6qeuMDrZwcEcEb63SQvrqr97lN+TpKzu/sHk/zrJG97gPOckeRvp7sLvzyVHZXkF7v7+6b9n+nupyXZmOQVVfXolbkEWBOWO9fOTHJVdz8pyaVJHjfX5jvmUnefkW/d4Xvxffq4OMkLkmQKD8cl+dMkpya5a+r7B5P8bFUdtkLXC7ul6VPZZye5McmvJ/lwdz8ls0+QLpyqvSrJ6d19ZJIfSvLV7e27++tJfi3JxdN8u3ju2F1Jrk/yw1PRjye5vLu/kdk/wl8+zd1XJXnL6l0lu8LH9QzT3V+sqguTvCJz/4NJ8qNJjqj65qtgH1VV37PM03+wuz8xt/+KqvrJafvQJIcn+fwuDBvWnF2Ya/8iyU9Obd9bVXfOtVnuXPqzJOdU1UOSnJjkL7v7q1V1fJKnVNX2j9X3m871iZ2cB9ayh1XV9dP2+5Ocl+SazP7hm+6+qqoeXVWPSvKBJL81fZr0ru6+bW6OPpCLk7wwyfsyexnhW6Y5/cwkfzh3noeswDWxggRwRvvtJB9K8va5sgclOaa7756vWFX35Ns/pXno/Zz3H+baPSuzoPGM7v5KVf3FA7SFPdFy5toOT7Arc6m7757qnZBZMLho++kyuyN3+XIvBNagr053tL9pZ/Osu8+qqj/NbJ33B6rqhCR377Dyd7osyX+pqgOTPC3JVUkekeQL9+2f3YslKAzV3duSXJLZx9Hb/XmSl2/fqart/9P4ZGZLS1JVRyXZ/nH1l5I88n662S/JnVNgeGKSY1Zk8LCGLHOufSDfWjZyfJIDpvL7m0vfqKoH76T7i5O8LLOP0987lV2e5N9tb1NV31dVj9jFy4O16P1JXpx88x+3n5s+rXp8d9/Y3a9Pcm2S+67X3unfvO7+8tTmnCR/0t33dvcXk3yiqp4/9VVV9QOrckXsMgGcRXhjkvknNLwiycbpiym35FvfFn9nkgOr6uYkv5Dkb5Kkuz+f2V2Cm6rqDTs4/3uTrKuqj2T2hc2rV+k6YHe31Ln260mOr6qbkjw/yacz+6N/f3Pp3CQ3bP8S5n38eWbrUv/XtIY1ma03vyXJh6Z+/nt8Csve5dVJnlZVN2Q2nzZN5a+c/p7dkOQbmS3jmve+zJaOXV9VL9zBeS9O8tPT7+1enOTUqvrrJDcnOXnlLoOV4E2YAHu5ab32vd19T1U9I8lbfXwNsHrcfQDgcUkumR5n9vUkP7vg8QDs0dwBBwCAgawBBwCAgQRwAAAYSAAHAICBBHAAUlVHVtVJc/vPqaozVrnPZ1XVM1ezD4DdkQAOQJIcmdmb+JIk3X1Zd5+1yn0+K7NXZgPsVTwFBWCNm94oeUmSQ5Lsk+S1SbYk+a0k35Pkc0le2t13TK+JvybJv0qyf2Zvyrxmqv+wJLcn+a/T9sbu/oWqekeSryZ5apJ/kuRnkrwkyTOSXNPdL53GcXxmL/V5SJK/TfKy7v5yVX0yyQVJfiLJgzN72c/dmb3Y594kWzN7Tf37V+O/D8Duxh1wgLXvxCR/390/0N1PzuwNlm9Ockp3Py3J+UleN1d/XXcfneSVSc6c3lb5a0ku7u4ju/vifKcDMgvcv5TksiRnJ3lSku+flq8clOQ/J/nR7j4qyeYk/36u/eem8rcmeVV3fzLJf0ty9tSn8A3sNbyIB2DtuzHJG6vq9Un+JMmdSZ6c5IqqSmZ3xe+Yq/+u6fd1STYssY8/7u6uqhuTfKa7b0ySqrp5OschSY5I8oGpz32T/NVO+nzeMq4NYI8jgAOscd39N1V1VGZruH8jyVVJbu7uZ+ykydem3/dm6X8Htrf5x7nt7fvrpnNd0d0/tYJ9AuyRLEEBWOOq6rFJvtLd/yPJG5I8Pcn6qnrGdPzBVfWkBzjNl5I88rsYxtVJjq2qJ0x9PqKqvm+V+wRYkwRwgLXv+5N8sKquT3JmZuu5T0ny+qr66yTX54GfNvK+JEdU1fVV9cLlDqC7tyZ5aZI/qKobMlt+8sQHaPbHSX5y6vOHltsnwFrlKSgAADCQO+AAADCQAA4AAAMJ4AAAMJAADgAAAwngAAAwkAAOAAADCeAAADCQAA4AAAP9fznuDyy069GxAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 864x360 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig_dims = (12, 5)\n",
        "fig, ax = plt.subplots(figsize=fig_dims)\n",
        "sns.countplot(data=df, x=\"sentiment\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "BHclUksEwTJD",
        "outputId": "1625c311-b583-487c-f6d2-abbf2b3ee7d1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-fcad6568-2bd9-4da4-90e2-6f93211571a3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>User</th>\n",
              "      <th>Tweet</th>\n",
              "      <th>cleaned_tweets</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TanseemHaider</td>\n",
              "      <td>RT @aajtak: ‡§ú‡•à‡§ï‡§≤‡•Ä‡§® ‡§´‡§∞‡•ç‡§®‡§æ‡§Ç‡§°‡•Ä‡§∏ ‡§®‡•á ‡§ï‡•ã‡§∞‡•ç‡§ü ‡§∏‡•á 15 ‡§¶‡§ø...</td>\n",
              "      <td>RT  ‡§ú‡•à‡§ï‡§≤‡•Ä‡§® ‡§´‡§∞‡•ç‡§®‡§æ‡§Ç‡§°‡•Ä‡§∏ ‡§®‡•á ‡§ï‡•ã‡§∞‡•ç‡§ü ‡§∏‡•á  ‡§¶‡§ø‡§® ‡§ï‡•á ‡§µ‡§ø‡§¶‡•á‡§∂...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sanjayyadav782</td>\n",
              "      <td>RT @OpIndia_in: ‚Äò‡§¨‡•â‡§≤‡•Ä‡§µ‡•Å‡§° ‡§Æ‡•Å‡§ù‡•á ‡§Ö‡§´‡•â‡§∞‡•ç‡§° ‡§®‡§π‡•Ä‡§Ç ‡§ï‡§∞ ‡§∏...</td>\n",
              "      <td>RT  ‚Äò‡§¨‡•â‡§≤‡•Ä‡§µ‡•Å‡§° ‡§Æ‡•Å‡§ù‡•á ‡§Ö‡§´‡•â‡§∞‡•ç‡§° ‡§®‡§π‡•Ä‡§Ç ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§â‡§®‡§ï‡•Ä ‡§´‡§º‡§ø...</td>\n",
              "      <td>Negative</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>chetanjoshi_</td>\n",
              "      <td>RT @thepaltan_: ‡§∏‡§Ç‡§µ‡•á‡§¶‡§®‡§∂‡•Ä‡§≤ ‡§Æ‡•Å‡§¶‡•ç‡§¶‡•ã‡§Ç ‡§™‡§∞ ‡§∏‡•É‡§ú‡§®‡§æ‡§§‡•ç‡§Æ‡§ï...</td>\n",
              "      <td>RT  ‡§∏‡§Ç‡§µ‡•á‡§¶‡§®‡§∂‡•Ä‡§≤ ‡§Æ‡•Å‡§¶‡•ç‡§¶‡•ã‡§Ç ‡§™‡§∞ ‡§∏‡•É‡§ú‡§®‡§æ‡§§‡•ç‡§Æ‡§ï ‡§™‡•ç‡§∞‡§π‡§æ‡§∞ ‡§ï‡§∞‡§§‡§æ...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>thepaltan_</td>\n",
              "      <td>‡§∏‡§Ç‡§µ‡•á‡§¶‡§®‡§∂‡•Ä‡§≤ ‡§Æ‡•Å‡§¶‡•ç‡§¶‡•ã‡§Ç ‡§™‡§∞ ‡§∏‡•É‡§ú‡§®‡§æ‡§§‡•ç‡§Æ‡§ï ‡§™‡•ç‡§∞‡§π‡§æ‡§∞ ‡§ï‡§∞‡§§‡§æ ‡§∏‡§ø‡§®...</td>\n",
              "      <td>‡§∏‡§Ç‡§µ‡•á‡§¶‡§®‡§∂‡•Ä‡§≤ ‡§Æ‡•Å‡§¶‡•ç‡§¶‡•ã‡§Ç ‡§™‡§∞ ‡§∏‡•É‡§ú‡§®‡§æ‡§§‡•ç‡§Æ‡§ï ‡§™‡•ç‡§∞‡§π‡§æ‡§∞ ‡§ï‡§∞‡§§‡§æ ‡§∏‡§ø‡§®...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RajivSanatni</td>\n",
              "      <td>RT @rowdy_pandit: üí•‡§ú‡§¨ ‡§¶‡§ø‡§ñ‡•á‡§ó‡§æ ‡§§‡§≠‡•Ä ‡§§‡•ã ‡§¨‡§ø‡§ï‡•á‡§ó‡§æ!!ü§ìüôÇ...</td>\n",
              "      <td>RT  üí•‡§ú‡§¨ ‡§¶‡§ø‡§ñ‡•á‡§ó‡§æ ‡§§‡§≠‡•Ä ‡§§‡•ã ‡§¨‡§ø‡§ï‡•á‡§ó‡§æü§ìüôÇüôÇ üí•üëâSimple logic...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21208</th>\n",
              "      <td>JuliusFlywheel</td>\n",
              "      <td>RT @redrabbleroz: I honestly still cannot get ...</td>\n",
              "      <td>RT  I honestly still cannot get over this How ...</td>\n",
              "      <td>Negative</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21209</th>\n",
              "      <td>gordonm25443977</td>\n",
              "      <td>RT @toryman1979: https://t.co/QDwRYKgtm7\\nTwin...</td>\n",
              "      <td>RT   Twin girls  found safe and well after goi...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21210</th>\n",
              "      <td>phorlerkemii</td>\n",
              "      <td>RT @Gistloversblog1: The comment I was looking...</td>\n",
              "      <td>RT  The comment I was looking for Firstly she ...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21211</th>\n",
              "      <td>Yashika_SidNaaz</td>\n",
              "      <td>RT @filmibeat: Tejasswi Prakash, Shehnaaz Gill...</td>\n",
              "      <td>RT  Tejasswi Prakash Shehnaaz Gill amp Anushka...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21212</th>\n",
              "      <td>WediRaya7</td>\n",
              "      <td>RT @E2buddy1: On this #MothersDay2022 Tigrayan...</td>\n",
              "      <td>RT  On this MothersDay Tigrayan mothers are go...</td>\n",
              "      <td>Negative</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>21213 rows √ó 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fcad6568-2bd9-4da4-90e2-6f93211571a3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fcad6568-2bd9-4da4-90e2-6f93211571a3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fcad6568-2bd9-4da4-90e2-6f93211571a3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                  User                                              Tweet  \\\n",
              "0        TanseemHaider  RT @aajtak: ‡§ú‡•à‡§ï‡§≤‡•Ä‡§® ‡§´‡§∞‡•ç‡§®‡§æ‡§Ç‡§°‡•Ä‡§∏ ‡§®‡•á ‡§ï‡•ã‡§∞‡•ç‡§ü ‡§∏‡•á 15 ‡§¶‡§ø...   \n",
              "1       sanjayyadav782  RT @OpIndia_in: ‚Äò‡§¨‡•â‡§≤‡•Ä‡§µ‡•Å‡§° ‡§Æ‡•Å‡§ù‡•á ‡§Ö‡§´‡•â‡§∞‡•ç‡§° ‡§®‡§π‡•Ä‡§Ç ‡§ï‡§∞ ‡§∏...   \n",
              "2         chetanjoshi_  RT @thepaltan_: ‡§∏‡§Ç‡§µ‡•á‡§¶‡§®‡§∂‡•Ä‡§≤ ‡§Æ‡•Å‡§¶‡•ç‡§¶‡•ã‡§Ç ‡§™‡§∞ ‡§∏‡•É‡§ú‡§®‡§æ‡§§‡•ç‡§Æ‡§ï...   \n",
              "3           thepaltan_  ‡§∏‡§Ç‡§µ‡•á‡§¶‡§®‡§∂‡•Ä‡§≤ ‡§Æ‡•Å‡§¶‡•ç‡§¶‡•ã‡§Ç ‡§™‡§∞ ‡§∏‡•É‡§ú‡§®‡§æ‡§§‡•ç‡§Æ‡§ï ‡§™‡•ç‡§∞‡§π‡§æ‡§∞ ‡§ï‡§∞‡§§‡§æ ‡§∏‡§ø‡§®...   \n",
              "4         RajivSanatni  RT @rowdy_pandit: üí•‡§ú‡§¨ ‡§¶‡§ø‡§ñ‡•á‡§ó‡§æ ‡§§‡§≠‡•Ä ‡§§‡•ã ‡§¨‡§ø‡§ï‡•á‡§ó‡§æ!!ü§ìüôÇ...   \n",
              "...                ...                                                ...   \n",
              "21208   JuliusFlywheel  RT @redrabbleroz: I honestly still cannot get ...   \n",
              "21209  gordonm25443977  RT @toryman1979: https://t.co/QDwRYKgtm7\\nTwin...   \n",
              "21210     phorlerkemii  RT @Gistloversblog1: The comment I was looking...   \n",
              "21211  Yashika_SidNaaz  RT @filmibeat: Tejasswi Prakash, Shehnaaz Gill...   \n",
              "21212        WediRaya7  RT @E2buddy1: On this #MothersDay2022 Tigrayan...   \n",
              "\n",
              "                                          cleaned_tweets sentiment  label  \n",
              "0      RT  ‡§ú‡•à‡§ï‡§≤‡•Ä‡§® ‡§´‡§∞‡•ç‡§®‡§æ‡§Ç‡§°‡•Ä‡§∏ ‡§®‡•á ‡§ï‡•ã‡§∞‡•ç‡§ü ‡§∏‡•á  ‡§¶‡§ø‡§® ‡§ï‡•á ‡§µ‡§ø‡§¶‡•á‡§∂...   Neutral      1  \n",
              "1      RT  ‚Äò‡§¨‡•â‡§≤‡•Ä‡§µ‡•Å‡§° ‡§Æ‡•Å‡§ù‡•á ‡§Ö‡§´‡•â‡§∞‡•ç‡§° ‡§®‡§π‡•Ä‡§Ç ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§â‡§®‡§ï‡•Ä ‡§´‡§º‡§ø...  Negative      0  \n",
              "2      RT  ‡§∏‡§Ç‡§µ‡•á‡§¶‡§®‡§∂‡•Ä‡§≤ ‡§Æ‡•Å‡§¶‡•ç‡§¶‡•ã‡§Ç ‡§™‡§∞ ‡§∏‡•É‡§ú‡§®‡§æ‡§§‡•ç‡§Æ‡§ï ‡§™‡•ç‡§∞‡§π‡§æ‡§∞ ‡§ï‡§∞‡§§‡§æ...   Neutral      1  \n",
              "3      ‡§∏‡§Ç‡§µ‡•á‡§¶‡§®‡§∂‡•Ä‡§≤ ‡§Æ‡•Å‡§¶‡•ç‡§¶‡•ã‡§Ç ‡§™‡§∞ ‡§∏‡•É‡§ú‡§®‡§æ‡§§‡•ç‡§Æ‡§ï ‡§™‡•ç‡§∞‡§π‡§æ‡§∞ ‡§ï‡§∞‡§§‡§æ ‡§∏‡§ø‡§®...   Neutral      1  \n",
              "4      RT  üí•‡§ú‡§¨ ‡§¶‡§ø‡§ñ‡•á‡§ó‡§æ ‡§§‡§≠‡•Ä ‡§§‡•ã ‡§¨‡§ø‡§ï‡•á‡§ó‡§æü§ìüôÇüôÇ üí•üëâSimple logic...  Positive      2  \n",
              "...                                                  ...       ...    ...  \n",
              "21208  RT  I honestly still cannot get over this How ...  Negative      0  \n",
              "21209  RT   Twin girls  found safe and well after goi...   Neutral      1  \n",
              "21210  RT  The comment I was looking for Firstly she ...   Neutral      1  \n",
              "21211  RT  Tejasswi Prakash Shehnaaz Gill amp Anushka...  Positive      2  \n",
              "21212  RT  On this MothersDay Tigrayan mothers are go...  Negative      0  \n",
              "\n",
              "[21213 rows x 5 columns]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def label(sentiment):\n",
        "  if sentiment == 'Negative':\n",
        "    return 0\n",
        "  elif sentiment == 'Neutral':\n",
        "    return 1\n",
        "  else:\n",
        "    return 2\n",
        "df['label'] = df['sentiment'].apply(label)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUGyQP4jl08p"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "df.sentiment = encoder.fit_transform(df.label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHI4QUyul6BT",
        "outputId": "1967b486-c42f-49a2-c41f-f128888ca9f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 0, 1, ..., 1, 2, 0])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "sentences = df.Tweet.values\n",
        "labels = df.label.values\n",
        "labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUzrVURDmBIP",
        "outputId": "a5a9dfca-db3c-4214-fc27-54b5a936149e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting SentencePiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[?25l\r\u001b[K     |‚ñé                               | 10 kB 19.5 MB/s eta 0:00:01\r\u001b[K     |‚ñå                               | 20 kB 23.4 MB/s eta 0:00:01\r\u001b[K     |‚ñâ                               | 30 kB 10.9 MB/s eta 0:00:01\r\u001b[K     |‚ñà                               | 40 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñç                              | 51 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñã                              | 61 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà                              | 71 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñè                             | 81 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñç                             | 92 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñä                             | 102 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà                             | 112 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñé                            | 122 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñå                            | 133 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñâ                            | 143 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà                            | 153 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñé                           | 163 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñã                           | 174 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñâ                           | 184 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                          | 194 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                          | 204 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                          | 215 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                          | 225 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                         | 235 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                         | 245 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                         | 256 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                         | 266 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                        | 276 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                        | 286 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                        | 296 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                        | 307 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                       | 317 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                       | 327 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                       | 337 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                      | 348 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                      | 358 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                      | 368 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                      | 378 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                     | 389 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                     | 399 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                     | 409 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                     | 419 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                    | 430 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                    | 440 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                    | 450 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                   | 460 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                   | 471 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                   | 481 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                   | 491 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                  | 501 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                  | 512 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                  | 522 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                  | 532 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                 | 542 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                 | 552 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                 | 563 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                | 573 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                | 583 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                | 593 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                | 604 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè               | 614 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå               | 624 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä               | 634 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà               | 645 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé              | 655 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå              | 665 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ              | 675 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà              | 686 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç             | 696 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã             | 706 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà             | 716 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè            | 727 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç            | 737 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä            | 747 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà            | 757 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé           | 768 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå           | 778 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ           | 788 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà           | 798 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé          | 808 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã          | 819 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ          | 829 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè         | 839 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç         | 849 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä         | 860 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà         | 870 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè        | 880 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå        | 890 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä        | 901 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà        | 911 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé       | 921 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã       | 931 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ       | 942 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà       | 952 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç      | 962 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã      | 972 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà      | 983 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè     | 993 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå     | 1.0 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä     | 1.0 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà     | 1.0 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1.0 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1.0 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1.2 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1.2 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1.2 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1.2 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1.2 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1.2 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.2 MB 5.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: SentencePiece\n",
            "Successfully installed SentencePiece-0.1.96\n"
          ]
        }
      ],
      "source": [
        "!pip install SentencePiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1ylkR0wmUAI",
        "outputId": "2b2bf946-5e9f-4063-fba7-4a070320ef3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading XLMRobertaTokenizer ...\n"
          ]
        }
      ],
      "source": [
        "from transformers import XLMRobertaTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading XLMRobertaTokenizer ...')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "3d057366910640c49ad26993204b8f4c",
            "82df0fda07394e85b7e5ee8e394bef15",
            "55a6b2d61a60422b9513c12032efc44d",
            "181f942b470c4639a2d9155b943fa63d",
            "e8fe740e2681457c8f4306bb9ba513d9",
            "3ae17179f7cd419a934b339f65285d61",
            "321a7632587548eabd7778d7c545be13",
            "47ce955325014c46b3ef2cfac51a3326",
            "657469901a724302a311a1a44c5b39da",
            "879f66d9edd54c4ca0c200b683265d97",
            "b24a7783af894e3baa6dae27199450a6",
            "ec22c2d66961498c9eb5a00557b7c460",
            "0453c2fed7e5446db6a8abf8d0231203",
            "c2e0126a7c9e46b7ac73f4aeea25d0b8",
            "4d4143c731ea46aeb1c8cca4fe4c2ed4",
            "98ec20796f0e4564ba65c715679e87be",
            "efed5f320e1149209435d40b63ab1b19",
            "8f069f427dfb4e1ca48b77014d1b0c98",
            "c9a5d5cc63394f0ba82c5b027e05cf0d",
            "b442aca8821b489b94d77b52bb2cf63c",
            "ae1fd1b7f3f84f3f89f13e901d80f8f6",
            "bc61318c588a41afbeaa9fefdb66b82e",
            "b2747665675649059f0a9c4238f91020",
            "d15f5545c40b45ec9de3e0d491aed8c4",
            "2503e76810c24234a0d6d7a6360e0a1e",
            "1814aa7a08d04d669514f0b340f8a71a",
            "1cdae369c0c04afabc9bdb288ef360b9",
            "e0f94188d898428ab428f8c2e1ea7aaa",
            "93f840ee54b54af7bb05763878f42c3d",
            "293f0e1158e742198edfe46145b9b767",
            "db43355570e547a9ad67efbfe3765a19",
            "cb8df9ef55654b82b19e28594316897e",
            "0fe538032245450a82e67f1817839b76"
          ]
        },
        "id": "GRXqo8-wmpLO",
        "outputId": "885299e5-2d7e-49b4-98d0-54676e79e306"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3d057366910640c49ad26993204b8f4c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/615 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ec22c2d66961498c9eb5a00557b7c460",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/4.83M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b2747665675649059f0a9c4238f91020",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/8.68M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForMaskedLM, AutoModelForSequenceClassification\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gcy5OBbooOqV",
        "outputId": "acf89c22-a61d-43ae-f3c1-17554ff63489"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Original:  RT @aajtak: ‡§ú‡•à‡§ï‡§≤‡•Ä‡§® ‡§´‡§∞‡•ç‡§®‡§æ‡§Ç‡§°‡•Ä‡§∏ ‡§®‡•á ‡§ï‡•ã‡§∞‡•ç‡§ü ‡§∏‡•á 15 ‡§¶‡§ø‡§® ‡§ï‡•á ‡§µ‡§ø‡§¶‡•á‡§∂ ‡§ü‡•Ç‡§∞ ‡§™‡§∞ ‡§ú‡§æ‡§®‡•á ‡§ï‡•Ä ‡§á‡§ú‡§æ‡§ú‡§§ ‡§Æ‡§æ‡§Ç‡§ó‡•Ä \n",
            "#JacquelineFernandez (@MunishPandeyy/@TanseemHaider)\n",
            "h‚Ä¶\n",
            "Tokenized:  ['‚ñÅRT', '‚ñÅ@', 'a', 'aj', 'tak', ':', '‚ñÅ‡§ú‡•à', '‡§ï‡§≤', '‡•Ä‡§®', '‚ñÅ‡§´‡§∞‡•ç', '‡§®‡§æ', '‡§Ç‡§°‡•Ä', '‡§∏', '‚ñÅ‡§®‡•á', '‚ñÅ‡§ï‡•ã‡§∞‡•ç‡§ü', '‚ñÅ‡§∏‡•á', '‚ñÅ15', '‚ñÅ‡§¶‡§ø‡§®', '‚ñÅ‡§ï‡•á', '‚ñÅ‡§µ‡§ø‡§¶‡•á‡§∂', '‚ñÅ‡§ü', '‡•Ç‡§∞', '‚ñÅ‡§™‡§∞', '‚ñÅ‡§ú‡§æ‡§®‡•á', '‚ñÅ‡§ï‡•Ä', '‚ñÅ‡§á', '‡§ú‡§æ', '‡§ú', '‡§§', '‚ñÅ‡§Æ‡§æ‡§Ç‡§ó', '‡•Ä', '‚ñÅ#', 'Ja', 'c', 'que', 'line', 'Fer', 'nan', 'dez', '‚ñÅ(@', 'Mu', 'nish', 'P', 'ande', 'yy', '/', '@', 'T', 'anse', 'em', 'H', 'aider', ')', '‚ñÅh', '...']\n",
            "Token IDs:  [27389, 1374, 11, 1122, 1865, 12, 127096, 28998, 32154, 106103, 1748, 106870, 1472, 1142, 43146, 646, 423, 3927, 287, 44893, 19315, 51303, 968, 13325, 471, 6698, 10886, 2410, 996, 45852, 659, 468, 6979, 238, 944, 2256, 89742, 4458, 26916, 41895, 10685, 78183, 683, 4431, 34034, 64, 981, 618, 20540, 195, 841, 135011, 16, 1096, 27]\n"
          ]
        }
      ],
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', sentences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMOKd-WHpP9e"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQQIWv8VpUqW",
        "outputId": "a4610841-d4a8-42c4-8117-680b4ade6f72"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original:  RT @aajtak: ‡§ú‡•à‡§ï‡§≤‡•Ä‡§® ‡§´‡§∞‡•ç‡§®‡§æ‡§Ç‡§°‡•Ä‡§∏ ‡§®‡•á ‡§ï‡•ã‡§∞‡•ç‡§ü ‡§∏‡•á 15 ‡§¶‡§ø‡§® ‡§ï‡•á ‡§µ‡§ø‡§¶‡•á‡§∂ ‡§ü‡•Ç‡§∞ ‡§™‡§∞ ‡§ú‡§æ‡§®‡•á ‡§ï‡•Ä ‡§á‡§ú‡§æ‡§ú‡§§ ‡§Æ‡§æ‡§Ç‡§ó‡•Ä \n",
            "#JacquelineFernandez (@MunishPandeyy/@TanseemHaider)\n",
            "h‚Ä¶\n",
            "Token IDs: tensor([     0,  27389,   1374,     11,   1122,   1865,     12, 127096,  28998,\n",
            "         32154, 106103,   1748, 106870,   1472,   1142,  43146,    646,    423,\n",
            "          3927,    287,  44893,  19315,  51303,    968,  13325,    471,   6698,\n",
            "         10886,   2410,    996,  45852,    659,    468,   6979,    238,    944,\n",
            "          2256,  89742,   4458,  26916,  41895,  10685,  78183,    683,   4431,\n",
            "         34034,     64,    981,    618,  20540,    195,    841, 135011,     16,\n",
            "          1096,     27,      2,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1])\n",
            "labels: tensor([1, 0, 1,  ..., 1, 2, 0])\n"
          ]
        }
      ],
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 128,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])\n",
        "print('labels:', labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9feOPZuqOF7",
        "outputId": "e26c366b-5765-42f4-e2ae-c9eb2e558b67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "14,849 training samples\n",
            "6,364 validation samples\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.7 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RoKRR-7DqSSf"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "48ccda9fa9874e17af021d35d7dda455",
            "0d997857904e4c1e981fa0073d1d5a20",
            "a25aaef9b2b14ecba1e17b3d072640d9",
            "08129fbab3c34ac48bfe22880fbe24e9",
            "fa4856f5292b430bb7198d1fc1a66cfc",
            "a2d23f182296421abf6f025af1f80c80",
            "cfe3fac72f274d63b8ef55cf4cb04f0d",
            "664a4af04ad5428b9d25638e3fe3333a",
            "5e849d75e24642bca4b27122901a754a",
            "25ab566f30b742329696e274c44b6065",
            "05484f0451144010b824b3d841d6ddba"
          ]
        },
        "id": "Pzuh79JjqYuD",
        "outputId": "d215ff96-6eb8-4c9e-bc66-0454cbd3c528"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "48ccda9fa9874e17af021d35d7dda455",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.04G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.layer_norm.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'roberta.pooler.dense.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.decoder.weight']\n",
            "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "XLMRobertaForSequenceClassification(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): RobertaClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import XLMRobertaForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = XLMRobertaForSequenceClassification.from_pretrained(\n",
        "    \"xlm-roberta-base\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 3, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNQ7CMIDsNh5",
        "outputId": "1c382c3f-b05b-4fda-a9aa-cb5a8c55ee20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The XLMRoberta model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "roberta.embeddings.word_embeddings.weight               (250002, 768)\n",
            "roberta.embeddings.position_embeddings.weight             (514, 768)\n",
            "roberta.embeddings.token_type_embeddings.weight             (1, 768)\n",
            "roberta.embeddings.LayerNorm.weight                           (768,)\n",
            "roberta.embeddings.LayerNorm.bias                             (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "roberta.encoder.layer.0.attention.self.query.weight       (768, 768)\n",
            "roberta.encoder.layer.0.attention.self.query.bias             (768,)\n",
            "roberta.encoder.layer.0.attention.self.key.weight         (768, 768)\n",
            "roberta.encoder.layer.0.attention.self.key.bias               (768,)\n",
            "roberta.encoder.layer.0.attention.self.value.weight       (768, 768)\n",
            "roberta.encoder.layer.0.attention.self.value.bias             (768,)\n",
            "roberta.encoder.layer.0.attention.output.dense.weight     (768, 768)\n",
            "roberta.encoder.layer.0.attention.output.dense.bias           (768,)\n",
            "roberta.encoder.layer.0.attention.output.LayerNorm.weight       (768,)\n",
            "roberta.encoder.layer.0.attention.output.LayerNorm.bias       (768,)\n",
            "roberta.encoder.layer.0.intermediate.dense.weight        (3072, 768)\n",
            "roberta.encoder.layer.0.intermediate.dense.bias              (3072,)\n",
            "roberta.encoder.layer.0.output.dense.weight              (768, 3072)\n",
            "roberta.encoder.layer.0.output.dense.bias                     (768,)\n",
            "roberta.encoder.layer.0.output.LayerNorm.weight               (768,)\n",
            "roberta.encoder.layer.0.output.LayerNorm.bias                 (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "classifier.dense.weight                                   (768, 768)\n",
            "classifier.dense.bias                                         (768,)\n",
            "classifier.out_proj.weight                                  (3, 768)\n",
            "classifier.out_proj.bias                                        (3,)\n"
          ]
        }
      ],
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The XLMRoberta model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIuP6j0csaAY",
        "outputId": "e08545aa-27fb-4787-d0a2-bade761c1c70"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7NhMaYk8sm3c"
      },
      "outputs": [],
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HwifNQLDsvtr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wouzF-ZaxJ2W"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zdm9Sb_JFTBP",
        "outputId": "1bedc700-ad98-4cb6-c08b-83acfb82339e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    465.    Elapsed: 0:00:55.\n",
            "  Batch    80  of    465.    Elapsed: 0:01:51.\n",
            "  Batch   120  of    465.    Elapsed: 0:02:47.\n",
            "  Batch   160  of    465.    Elapsed: 0:03:42.\n",
            "  Batch   200  of    465.    Elapsed: 0:04:38.\n",
            "  Batch   240  of    465.    Elapsed: 0:05:33.\n",
            "  Batch   280  of    465.    Elapsed: 0:06:28.\n",
            "  Batch   320  of    465.    Elapsed: 0:07:24.\n",
            "  Batch   360  of    465.    Elapsed: 0:08:19.\n",
            "  Batch   400  of    465.    Elapsed: 0:09:15.\n",
            "  Batch   440  of    465.    Elapsed: 0:10:11.\n",
            "\n",
            "  Average training loss: 0.65\n",
            "  Training epcoh took: 0:10:44\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.82\n",
            "  Validation Loss: 0.45\n",
            "  Validation took: 0:01:30\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    465.    Elapsed: 0:00:55.\n",
            "  Batch    80  of    465.    Elapsed: 0:01:51.\n",
            "  Batch   120  of    465.    Elapsed: 0:02:47.\n",
            "  Batch   160  of    465.    Elapsed: 0:03:42.\n",
            "  Batch   200  of    465.    Elapsed: 0:04:37.\n",
            "  Batch   240  of    465.    Elapsed: 0:05:33.\n",
            "  Batch   280  of    465.    Elapsed: 0:06:28.\n",
            "  Batch   320  of    465.    Elapsed: 0:07:24.\n",
            "  Batch   360  of    465.    Elapsed: 0:08:19.\n",
            "  Batch   400  of    465.    Elapsed: 0:09:15.\n",
            "  Batch   440  of    465.    Elapsed: 0:10:10.\n",
            "\n",
            "  Average training loss: 0.39\n",
            "  Training epcoh took: 0:10:44\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.39\n",
            "  Validation took: 0:01:31\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    465.    Elapsed: 0:00:56.\n",
            "  Batch    80  of    465.    Elapsed: 0:01:51.\n",
            "  Batch   120  of    465.    Elapsed: 0:02:46.\n",
            "  Batch   160  of    465.    Elapsed: 0:03:42.\n",
            "  Batch   200  of    465.    Elapsed: 0:04:37.\n",
            "  Batch   240  of    465.    Elapsed: 0:05:33.\n",
            "  Batch   280  of    465.    Elapsed: 0:06:28.\n",
            "  Batch   320  of    465.    Elapsed: 0:07:24.\n",
            "  Batch   360  of    465.    Elapsed: 0:08:19.\n",
            "  Batch   400  of    465.    Elapsed: 0:09:15.\n",
            "  Batch   440  of    465.    Elapsed: 0:10:10.\n",
            "\n",
            "  Average training loss: 0.27\n",
            "  Training epcoh took: 0:10:44\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.42\n",
            "  Validation took: 0:01:31\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    465.    Elapsed: 0:00:56.\n",
            "  Batch    80  of    465.    Elapsed: 0:01:51.\n",
            "  Batch   120  of    465.    Elapsed: 0:02:46.\n",
            "  Batch   160  of    465.    Elapsed: 0:03:42.\n",
            "  Batch   200  of    465.    Elapsed: 0:04:37.\n",
            "  Batch   240  of    465.    Elapsed: 0:05:33.\n",
            "  Batch   280  of    465.    Elapsed: 0:06:28.\n",
            "  Batch   320  of    465.    Elapsed: 0:07:24.\n",
            "  Batch   360  of    465.    Elapsed: 0:08:19.\n",
            "  Batch   400  of    465.    Elapsed: 0:09:15.\n",
            "  Batch   440  of    465.    Elapsed: 0:10:10.\n",
            "\n",
            "  Average training loss: 0.19\n",
            "  Training epcoh took: 0:10:44\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "  Validation Loss: 0.45\n",
            "  Validation took: 0:01:31\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:48:58 (h:mm:ss)\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # It returns different numbers of parameters depending on what arguments\n",
        "        # arge given and what flags are set. For our useage here, it returns\n",
        "        # the loss (because we provided labels) and the \"logits\"--the model\n",
        "        # outputs prior to activation.\n",
        "        loss, logits = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels, return_dict=False)\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            (loss, logits) = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels, return_dict=False)\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "\n",
        "        \n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "LyrN9OkwYG1P",
        "outputId": "fe62ebe2-c79d-4feb-f59b-de768c5d6cbf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.65         0.45           0.82       0:10:44         0:01:30\n",
              "2               0.39         0.39           0.84       0:10:44         0:01:31\n",
              "3               0.27         0.42           0.84       0:10:44         0:01:31\n",
              "4               0.19         0.45           0.85       0:10:44         0:01:31"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8203d718-a2be-4a60-bac4-edb5dfeb1d6f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.65</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.82</td>\n",
              "      <td>0:10:44</td>\n",
              "      <td>0:01:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.39</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0:10:44</td>\n",
              "      <td>0:01:31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.27</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0:10:44</td>\n",
              "      <td>0:01:31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.19</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0:10:44</td>\n",
              "      <td>0:01:31</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8203d718-a2be-4a60-bac4-edb5dfeb1d6f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8203d718-a2be-4a60-bac4-edb5dfeb1d6f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8203d718-a2be-4a60-bac4-edb5dfeb1d6f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "H8y-iFDzYLOl",
        "outputId": "f3825fe4-42c2-44e4-f2d0-7b8f5fe6ac3a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMgohy6oZMh5",
        "outputId": "6b365dd7-8baf-403f-ad3c-10bd33701800"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model to /content/drive/MyDrive/major-final/xlm-roberta_model_save\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/major-final/xlm-roberta_model_save/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/major-final/xlm-roberta_model_save/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/major-final/xlm-roberta_model_save/sentencepiece.bpe.model',\n",
              " '/content/drive/MyDrive/major-final/xlm-roberta_model_save/added_tokens.json',\n",
              " '/content/drive/MyDrive/major-final/xlm-roberta_model_save/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "output_dir = '/content/drive/MyDrive/major-final/xlm-roberta_model_save'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "# Good practice: save your training arguments together with the trained model\n",
        "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zs_GIXyGZfia",
        "outputId": "f55f4760-790f-4ad1-f69c-a887589d8f35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.5.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.53)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "/content/drive/MyDrive/major-final/xlm-roberta_model_save\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "\n",
        "from transformers import XLMRobertaForSequenceClassification\n",
        "\n",
        "output_dir = '/content/drive/MyDrive/major-final/xlm-roberta_model_save'\n",
        "\n",
        "print(output_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCDks1CEZnj8",
        "outputId": "d083c7d3-56aa-4c44-bf8a-1d2ea432032a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading XLMRobertaTokenizer...\n"
          ]
        }
      ],
      "source": [
        "from transformers import XLMRobertaTokenizer\n",
        "import torch\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading XLMRobertaTokenizer...')\n",
        "tokenizer = XLMRobertaTokenizer.from_pretrained(output_dir)\n",
        "model_loaded = XLMRobertaForSequenceClassification.from_pretrained(output_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6zn_gqLaAPE",
        "outputId": "0d355912-bdb8-4359-f2cd-d4c0aae55437"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "# Let's check it for a given sentence\n",
        "encoded_dict = tokenizer.encode_plus(\n",
        "                        \"Everything is going normal as per requirement.\",                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 64,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "input_id = encoded_dict['input_ids']\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "attention_mask = encoded_dict['attention_mask']\n",
        "input_id = torch.LongTensor(input_id)\n",
        "attention_mask = torch.LongTensor(attention_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CltRSuIzadfu"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_loaded = model_loaded.to(device)\n",
        "input_id = input_id.to(device)\n",
        "attention_mask = attention_mask.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpw7mzgQad5i",
        "outputId": "746e7a64-90a5-4865-92cc-6651d2b91804"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neutral Sentiment\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "  # Forward pass, calculate logit predictions\n",
        "  outputs = model_loaded(input_id, token_type_ids=None, attention_mask=attention_mask)\n",
        "  #print(outputs[0])\n",
        "logits = outputs[0]\n",
        "index = logits.argmax()\n",
        "\n",
        "if index == 0:\n",
        "  print(\"Negative Sentiment\")\n",
        "elif index==1:\n",
        "  print(\"Neutral Sentiment\")\n",
        "elif index==2:\n",
        "  print(\"Positive Sentiment\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P1ZY3KI3a1cb"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0453c2fed7e5446db6a8abf8d0231203": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_efed5f320e1149209435d40b63ab1b19",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_8f069f427dfb4e1ca48b77014d1b0c98",
            "value": "Downloading: 100%"
          }
        },
        "05484f0451144010b824b3d841d6ddba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "08129fbab3c34ac48bfe22880fbe24e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25ab566f30b742329696e274c44b6065",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_05484f0451144010b824b3d841d6ddba",
            "value": " 1.04G/1.04G [00:31&lt;00:00, 36.4MB/s]"
          }
        },
        "0d997857904e4c1e981fa0073d1d5a20": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2d23f182296421abf6f025af1f80c80",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_cfe3fac72f274d63b8ef55cf4cb04f0d",
            "value": "Downloading: 100%"
          }
        },
        "0fe538032245450a82e67f1817839b76": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1814aa7a08d04d669514f0b340f8a71a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb8df9ef55654b82b19e28594316897e",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_0fe538032245450a82e67f1817839b76",
            "value": " 8.68M/8.68M [00:00&lt;00:00, 12.6MB/s]"
          }
        },
        "181f942b470c4639a2d9155b943fa63d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_879f66d9edd54c4ca0c200b683265d97",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_b24a7783af894e3baa6dae27199450a6",
            "value": " 615/615 [00:00&lt;00:00, 11.1kB/s]"
          }
        },
        "1cdae369c0c04afabc9bdb288ef360b9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2503e76810c24234a0d6d7a6360e0a1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_293f0e1158e742198edfe46145b9b767",
            "max": 9096718,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_db43355570e547a9ad67efbfe3765a19",
            "value": 9096718
          }
        },
        "25ab566f30b742329696e274c44b6065": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "293f0e1158e742198edfe46145b9b767": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "321a7632587548eabd7778d7c545be13": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ae17179f7cd419a934b339f65285d61": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d057366910640c49ad26993204b8f4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_82df0fda07394e85b7e5ee8e394bef15",
              "IPY_MODEL_55a6b2d61a60422b9513c12032efc44d",
              "IPY_MODEL_181f942b470c4639a2d9155b943fa63d"
            ],
            "layout": "IPY_MODEL_e8fe740e2681457c8f4306bb9ba513d9"
          }
        },
        "47ce955325014c46b3ef2cfac51a3326": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48ccda9fa9874e17af021d35d7dda455": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0d997857904e4c1e981fa0073d1d5a20",
              "IPY_MODEL_a25aaef9b2b14ecba1e17b3d072640d9",
              "IPY_MODEL_08129fbab3c34ac48bfe22880fbe24e9"
            ],
            "layout": "IPY_MODEL_fa4856f5292b430bb7198d1fc1a66cfc"
          }
        },
        "4d4143c731ea46aeb1c8cca4fe4c2ed4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae1fd1b7f3f84f3f89f13e901d80f8f6",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_bc61318c588a41afbeaa9fefdb66b82e",
            "value": " 4.83M/4.83M [00:00&lt;00:00, 8.60MB/s]"
          }
        },
        "55a6b2d61a60422b9513c12032efc44d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47ce955325014c46b3ef2cfac51a3326",
            "max": 615,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_657469901a724302a311a1a44c5b39da",
            "value": 615
          }
        },
        "5e849d75e24642bca4b27122901a754a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "657469901a724302a311a1a44c5b39da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "664a4af04ad5428b9d25638e3fe3333a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82df0fda07394e85b7e5ee8e394bef15": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ae17179f7cd419a934b339f65285d61",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_321a7632587548eabd7778d7c545be13",
            "value": "Downloading: 100%"
          }
        },
        "879f66d9edd54c4ca0c200b683265d97": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f069f427dfb4e1ca48b77014d1b0c98": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "93f840ee54b54af7bb05763878f42c3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "98ec20796f0e4564ba65c715679e87be": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a25aaef9b2b14ecba1e17b3d072640d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_664a4af04ad5428b9d25638e3fe3333a",
            "max": 1115590446,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5e849d75e24642bca4b27122901a754a",
            "value": 1115590446
          }
        },
        "a2d23f182296421abf6f025af1f80c80": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae1fd1b7f3f84f3f89f13e901d80f8f6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b24a7783af894e3baa6dae27199450a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b2747665675649059f0a9c4238f91020": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d15f5545c40b45ec9de3e0d491aed8c4",
              "IPY_MODEL_2503e76810c24234a0d6d7a6360e0a1e",
              "IPY_MODEL_1814aa7a08d04d669514f0b340f8a71a"
            ],
            "layout": "IPY_MODEL_1cdae369c0c04afabc9bdb288ef360b9"
          }
        },
        "b442aca8821b489b94d77b52bb2cf63c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bc61318c588a41afbeaa9fefdb66b82e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c2e0126a7c9e46b7ac73f4aeea25d0b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9a5d5cc63394f0ba82c5b027e05cf0d",
            "max": 5069051,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b442aca8821b489b94d77b52bb2cf63c",
            "value": 5069051
          }
        },
        "c9a5d5cc63394f0ba82c5b027e05cf0d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb8df9ef55654b82b19e28594316897e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfe3fac72f274d63b8ef55cf4cb04f0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d15f5545c40b45ec9de3e0d491aed8c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0f94188d898428ab428f8c2e1ea7aaa",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_93f840ee54b54af7bb05763878f42c3d",
            "value": "Downloading: 100%"
          }
        },
        "db43355570e547a9ad67efbfe3765a19": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e0f94188d898428ab428f8c2e1ea7aaa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8fe740e2681457c8f4306bb9ba513d9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec22c2d66961498c9eb5a00557b7c460": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0453c2fed7e5446db6a8abf8d0231203",
              "IPY_MODEL_c2e0126a7c9e46b7ac73f4aeea25d0b8",
              "IPY_MODEL_4d4143c731ea46aeb1c8cca4fe4c2ed4"
            ],
            "layout": "IPY_MODEL_98ec20796f0e4564ba65c715679e87be"
          }
        },
        "efed5f320e1149209435d40b63ab1b19": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa4856f5292b430bb7198d1fc1a66cfc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}